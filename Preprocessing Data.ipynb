{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the packages you will need to unpack the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import os\n",
    "import zipfile\n",
    "import scipy.ndimage\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are these energy bars</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are these waters</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are these waters</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are these cheetos</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>are these apples</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>are these chocolate drinks</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>are these beans</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>are these puddings</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>are these energy bars</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>are these condiments</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>are these apples</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>are these chocolate drinks</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>are these cupcakes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>are these cereals</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>are these energy bars</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>are these breakfast foods</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>are these energy bars</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>are these soups</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>are these cheetos</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>are these pills</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>are these tomatoes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>are these juices</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>are these soups</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>are these pot pies</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>are these muffins</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>are these muffins</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655</th>\n",
       "      <td>are these pretzels</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>are these pills</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>are these chips</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4660 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question answer\n",
       "0          are these energy bars     no\n",
       "1               are these waters     no\n",
       "2               are these waters     no\n",
       "3              are these cheetos     no\n",
       "4               are these juices    yes\n",
       "5               are these juices    yes\n",
       "6               are these apples     no\n",
       "7               are these juices    yes\n",
       "8               are these juices    yes\n",
       "9               are these juices    yes\n",
       "10              are these juices    yes\n",
       "11    are these chocolate drinks     no\n",
       "12              are these juices    yes\n",
       "13               are these beans     no\n",
       "14              are these juices    yes\n",
       "15              are these juices    yes\n",
       "16               are these chips     no\n",
       "17            are these puddings     no\n",
       "18              are these juices    yes\n",
       "19              are these juices    yes\n",
       "20              are these juices    yes\n",
       "21              are these juices    yes\n",
       "22         are these energy bars     no\n",
       "23              are these juices    yes\n",
       "24          are these condiments     no\n",
       "25              are these apples     no\n",
       "26              are these juices    yes\n",
       "27              are these juices    yes\n",
       "28    are these chocolate drinks     no\n",
       "29              are these juices    yes\n",
       "...                          ...    ...\n",
       "4630             are these chips    yes\n",
       "4631          are these cupcakes     no\n",
       "4632           are these cereals     no\n",
       "4633             are these chips    yes\n",
       "4634             are these chips    yes\n",
       "4635       are these energy bars     no\n",
       "4636             are these chips    yes\n",
       "4637             are these chips    yes\n",
       "4638             are these chips    yes\n",
       "4639   are these breakfast foods     no\n",
       "4640             are these chips    yes\n",
       "4641       are these energy bars     no\n",
       "4642             are these soups     no\n",
       "4643           are these cheetos     no\n",
       "4644             are these chips    yes\n",
       "4645             are these pills     no\n",
       "4646             are these chips    yes\n",
       "4647          are these tomatoes     no\n",
       "4648            are these juices     no\n",
       "4649             are these soups     no\n",
       "4650          are these pot pies     no\n",
       "4651           are these muffins     no\n",
       "4652             are these chips    yes\n",
       "4653             are these chips    yes\n",
       "4654           are these muffins     no\n",
       "4655          are these pretzels     no\n",
       "4656             are these chips    yes\n",
       "4657             are these chips    yes\n",
       "4658             are these pills     no\n",
       "4659             are these chips    yes\n",
       "\n",
       "[4660 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"vqa_mixed_yes_no_1.csv\").iloc[:, 1:]\n",
    "# Preview the first 5 lines of the loaded data \n",
    "data.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4660, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the dictionary\n",
    "pkl_file = open(\"word_index_VQA_3.pickle\", 'rb')\n",
    "word_index = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 6,\n",
       " 'an': 8,\n",
       " 'apple': 57,\n",
       " 'apples': 58,\n",
       " 'are': 3,\n",
       " 'banana': 74,\n",
       " 'bananas': 76,\n",
       " 'bar': 13,\n",
       " 'bars': 14,\n",
       " 'bean': 35,\n",
       " 'beans': 36,\n",
       " 'beef': 7,\n",
       " 'beefs': 73,\n",
       " 'breakfast': 11,\n",
       " 'cereal': 33,\n",
       " 'cereals': 34,\n",
       " 'cheese': 75,\n",
       " 'cheeses': 77,\n",
       " 'cheeto': 46,\n",
       " 'cheetos': 49,\n",
       " 'chip': 9,\n",
       " 'chips': 10,\n",
       " 'chocolate': 15,\n",
       " 'condiment': 16,\n",
       " 'condiments': 17,\n",
       " 'cookie': 25,\n",
       " 'cookies': 26,\n",
       " 'cupcake': 29,\n",
       " 'cupcakes': 30,\n",
       " 'drink': 45,\n",
       " 'drinks': 48,\n",
       " 'egg': 80,\n",
       " 'eggs': 81,\n",
       " 'energy': 12,\n",
       " 'food': 41,\n",
       " 'foods': 42,\n",
       " 'granola': 21,\n",
       " 'is': 1,\n",
       " 'jerkies': 64,\n",
       " 'jerky': 63,\n",
       " 'juice': 31,\n",
       " 'juices': 32,\n",
       " 'mac': 27,\n",
       " 'milk': 37,\n",
       " 'milks': 38,\n",
       " 'muffin': 65,\n",
       " 'muffins': 67,\n",
       " 'mushroom': 82,\n",
       " 'mushrooms': 83,\n",
       " 'n': 28,\n",
       " 'noodle': 51,\n",
       " 'noodles': 52,\n",
       " 'nut': 84,\n",
       " 'nuts': 85,\n",
       " 'pie': 61,\n",
       " 'pies': 62,\n",
       " 'pill': 19,\n",
       " 'pills': 20,\n",
       " 'pizza': 47,\n",
       " 'pizzas': 50,\n",
       " 'pot': 18,\n",
       " 'pretzel': 59,\n",
       " 'pretzels': 60,\n",
       " 'pudding': 53,\n",
       " 'puddings': 54,\n",
       " 'raw': 22,\n",
       " 'salt': 71,\n",
       " 'salts': 72,\n",
       " 'soda': 23,\n",
       " 'sodas': 24,\n",
       " 'soup': 69,\n",
       " 'soups': 70,\n",
       " 'sugar': 66,\n",
       " 'sugars': 68,\n",
       " 'these': 4,\n",
       " 'this': 2,\n",
       " 'tomato': 86,\n",
       " 'tomatoes': 79,\n",
       " 'tuna': 55,\n",
       " 'tunas': 56,\n",
       " 'water': 39,\n",
       " 'waters': 40,\n",
       " 'what': 5,\n",
       " 'yogurt': 43,\n",
       " 'yogurts': 44}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updating the Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## updating the dictionary if new words were added to the dataset\n",
    "\n",
    "file = open('new_questions.txt', 'r')\n",
    "\n",
    "curr_index = len(word_index)\n",
    "\n",
    "for line in file:\n",
    "    words = line.split(' ')\n",
    "    for w in words:\n",
    "        if(w not in word_index.keys):\n",
    "            word_index.update({w: curr_index})\n",
    "            curr_index+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### update words more easily\n",
    "\n",
    "word_index.update({'jerkies': 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove words if necessary\n",
    "w = 'tomatos'\n",
    "\n",
    "indices.append(word_index[w])\n",
    "del word_index[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.append(78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87, 78]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the file\n",
    "pickle_out = open(\"word_index_VQA_3.pickle\", \"wb\")\n",
    "pickle.dump(word_index, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting Questions to Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  4. 12. 14.]\n",
      " [ 0.  0.  0. ...  3.  4. 40.]\n",
      " [ 0.  0.  0. ...  3.  4. 40.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  3.  4. 10.]\n",
      " [ 0.  0.  0. ...  3.  4. 20.]\n",
      " [ 0.  0.  0. ...  3.  4. 10.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4660, 50)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create a sequence for each new question and pad to length 50\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "all_seq = np.zeros((4660, 50))\n",
    "i = 0\n",
    "for q in data['question']:\n",
    "    #print('hi')\n",
    "    words = q.split(' ')\n",
    "    new_seq = []\n",
    "    for w in words:\n",
    "        new_seq.append(word_index.get(w))\n",
    "    all_seq[i][-len(new_seq):]= new_seq\n",
    "    i+=1\n",
    "print(np.asarray(all_seq))\n",
    "trans_all_qs = pad_sequences(all_seq, maxlen=50)\n",
    "trans_all_qs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHERWISE, load the data\n",
    "file = open(\"ans_index_VQA_4.pickle\", \"rb\")\n",
    "ans_class = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 31,\n",
       " 'banana': 5,\n",
       " 'bean': 4,\n",
       " 'beef jerky': 6,\n",
       " 'breakfast food': 20,\n",
       " 'cereal': 9,\n",
       " 'cheeto': 22,\n",
       " 'chip': 10,\n",
       " 'chocolate drink': 23,\n",
       " 'condiment': 21,\n",
       " 'cookie': 12,\n",
       " 'cupcake': 13,\n",
       " 'egg': 17,\n",
       " 'energy bar': 18,\n",
       " 'granola bar': 11,\n",
       " 'juice': 2,\n",
       " 'mac n cheese': 24,\n",
       " 'milk': 14,\n",
       " 'muffin': 15,\n",
       " 'mushroom': 25,\n",
       " 'no': 1,\n",
       " 'noodle': 8,\n",
       " 'nut': 26,\n",
       " 'pill': 19,\n",
       " 'pizza': 27,\n",
       " 'pot pie': 28,\n",
       " 'pretzel': 29,\n",
       " 'pudding': 30,\n",
       " 'raw beef': 7,\n",
       " 'salt': 32,\n",
       " 'soda': 16,\n",
       " 'soup': 36,\n",
       " 'sugar': 34,\n",
       " 'tomato': 35,\n",
       " 'tuna': 37,\n",
       " 'water': 3,\n",
       " 'yes': 0,\n",
       " 'yogurt': 33}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO THIS ONCE, converting the answers into one hot encode and saving the answer IDs!\n",
    "import pickle\n",
    "\n",
    "ID = []\n",
    "for i in range(data.shape[0]):\n",
    "    ID.append(ans_class[data['answer'][i]])\n",
    "one_hot_labels = tf.keras.utils.to_categorical(ID)\n",
    "\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if not the right size, expand\n",
    "z = np.zeros((one_hot_labels.shape[0], len(ans_class.keys())), dtype=one_hot_labels.dtype)\n",
    "z[:, :2] = one_hot_labels\n",
    "one_hot_labels = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels.shape\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF ANS_CLASS ALREADY EXISTS, add the new answers\n",
    "file = open('new_answers.txt', 'r')\n",
    "\n",
    "curr_index = len(word_index)\n",
    "\n",
    "answer_set = set(ans_class)\n",
    "for line in file:\n",
    "    if line not in answer_set:\n",
    "        ans_class.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ans_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-09b13eb0e929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Saving the ANS_CLASS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpickle_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ans_index_only_yes.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ans_index' is not defined"
     ]
    }
   ],
   "source": [
    "## Saving the ANS_CLASS\n",
    "pickle_out = open(\"ans_index_only_yes.pickle\", \"wb\")\n",
    "pickle.dump(ans_index, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO THIS ONCE\n",
    "### getting all the pickle files and combining them into one training list\n",
    "train_imgs = []\n",
    "\n",
    "with open('imgs_0_1000.p', \"rb\") as input_file:\n",
    "    train_imgs = pickle.load(input_file)\n",
    "\n",
    "train_imgs2 = []\n",
    "with open('imgs_1000_2000.p', \"rb\") as input_file:\n",
    "    train_imgs2 = pickle.load(input_file)\n",
    "\n",
    "train_imgs3 = []\n",
    "with open('imgs_2000_3000.p', \"rb\") as input_file:\n",
    "    train_imgs3 = pickle.load(input_file)\n",
    "\n",
    "train_imgs4 = []\n",
    "with open('imgs_3000_4000.p', \"rb\") as input_file:\n",
    "    train_imgs4 = pickle.load(input_file)\n",
    "\n",
    "train_imgs5 = []\n",
    "with open('imgs_4000_remaining.p', \"rb\") as input_file:\n",
    "    train_imgs5 = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO THIS ONCE\n",
    "all_train_imgs = train_imgs + train_imgs2 + train_imgs3 + train_imgs4 + train_imgs5\n",
    "\n",
    "all_qs = data['question']\n",
    "\n",
    "all_imgs = np.asarray(all_train_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test, Train, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### may want to run this multiple times, split the questions and images into training, validation, testing\n",
    "arr = np.arange(all_imgs.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "test_ind = arr[0:arr.shape[0]//5]\n",
    "val_ind = arr[arr.shape[0]//5: 9* arr.shape[0]//25]\n",
    "train_ind = arr[9*arr.shape[0]//25:arr.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change the multiplier of the indices\n",
    "## append the new questions and answers to the current\n",
    "\n",
    "# change this value if necessary\n",
    "k = 0\n",
    "\n",
    "train_ind2 = train_ind+arr.shape[0]*k\n",
    "test_ind2 = test_ind + arr.shape[0]*k\n",
    "val_ind2 = val_ind + arr.shape[0]*k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qs = trans_all_qs[train_ind2]\n",
    "val_qs = trans_all_qs[val_ind2]\n",
    "test_qs = trans_all_qs[test_ind2]\n",
    "\n",
    "\n",
    "\n",
    "train_ans = one_hot_labels[train_ind2]\n",
    "val_ans = one_hot_labels[val_ind2]\n",
    "test_ans = one_hot_labels[test_ind2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ims = all_imgs[train_ind]\n",
    "val_ims = all_imgs[val_ind]\n",
    "test_imgs = all_imgs[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the current npy file (first iteration)\n",
    "np.save(\"train_qs_6_5.npy\", train_qs)\n",
    "np.save(\"val_qs_6_5.npy\", val_qs)\n",
    "np.save(\"test_qs_6_5.npy\", test_qs)\n",
    "\n",
    "np.save(\"train_ims_6_5.npy\", train_ims)\n",
    "np.save(\"val_ims_6_5.npy\", val_ims)\n",
    "np.save(\"test_ims_6_5.npy\", test_imgs)\n",
    "\n",
    "np.save(\"train_ans_6_5.npy\", train_ans)\n",
    "np.save(\"val_ans_6_5.npy\", val_ans)\n",
    "np.save(\"test_ans_6_5.npy\", test_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the current arrays\n",
    "train_qs = np.load(\"train_qs_4_3.npy\")\n",
    "val_qs = np.load(\"val_qs_4_3.npy\")\n",
    "test_qs = np.load(\"test_qs_4.npy\")\n",
    "\n",
    "train_ans = np.load(\"train_ans_4_3.npy\")\n",
    "val_ans = np.load(\"val_ans_4_3.npy\")\n",
    "test_ans = np.load(\"test_ans_4_3.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qs = np.concatenate((train_qs, trans_all_qs[train_ind2]), axis = 0)\n",
    "val_qs = np.concatenate((val_qs, trans_all_qs[val_ind2]), axis = 0)\n",
    "test_qs = np.concatenate((test_qs, trans_all_qs[test_ind2]), axis = 0)\n",
    "\n",
    "train_ans = np.concatenate((train_ans, one_hot_labels[train_ind2]), axis = 0)\n",
    "val_ans = np.concatenate((val_ans, one_hot_labels[val_ind2]), axis = 0)\n",
    "test_ans = np.concatenate((test_ans, one_hot_labels[test_ind2]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8949, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
